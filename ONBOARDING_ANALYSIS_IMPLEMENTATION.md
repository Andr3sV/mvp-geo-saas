# ‚úÖ Implementaci√≥n: Onboarding con An√°lisis Autom√°tico

## üéØ Objetivo Completado

Se ha implementado exitosamente el flujo completo donde los prompts creados en el onboarding:
1. ‚úÖ Se guardan en la base de datos
2. ‚úÖ Disparan an√°lisis autom√°tico con todos los LLMs (OpenAI, Gemini, Claude, Perplexity)
3. ‚úÖ Se visualizan en Prompt Management
4. ‚úÖ Los resultados se muestran en Citation Tracking

---

## üîß Cambios Implementados

### 1. **Modificaci√≥n en `src/lib/actions/workspace.ts`**

**Funci√≥n `savePrompts`:**
```typescript
// ANTES: Solo insertaba prompts
const { error } = await supabase.from("prompt_tracking").insert(promptsData);
return { error: null, success: true };

// AHORA: Retorna los prompts creados con sus IDs
const { data: createdPrompts, error } = await supabase
  .from("prompt_tracking")
  .insert(promptsData)
  .select();

return { error: null, success: true, data: createdPrompts };
```

**Beneficio:** Ahora podemos obtener los IDs de los prompts creados para disparar el an√°lisis.

---

### 2. **Modificaci√≥n en `src/app/onboarding/page.tsx`**

**Importaci√≥n de `startAnalysis`:**
```typescript
import { startAnalysis, type AIProvider } from "@/lib/actions/analysis";
```

**Funci√≥n `handleStep4Submit` mejorada:**
```typescript
const result = await savePrompts({
  project_id: projectId!,
  prompts: selectedPrompts.map((p) => ({
    prompt: p.text,
    region: p.region,
    category: p.category,
  })),
});

if (result.error) {
  setError(result.error);
  setLoading(false);
  return;
}

// ‚ú® NUEVO: Disparar an√°lisis autom√°tico
if (result.data && result.data.length > 0) {
  const allPlatforms: AIProvider[] = ["openai", "gemini", "claude", "perplexity"];
  
  result.data.forEach((prompt: any) => {
    startAnalysis({
      prompt_tracking_id: prompt.id,
      project_id: projectId!,
      prompt_text: prompt.prompt,
      platforms: allPlatforms,
    }).catch((error) => {
      console.error("Failed to start analysis for prompt:", prompt.id, error);
    });
  });
}
```

**Beneficio:** 
- Cada prompt creado dispara autom√°ticamente el an√°lisis con los 4 LLMs
- El an√°lisis se ejecuta en background (no bloquea la UI)
- Los errores se capturan y se registran en consola

---

## üß™ C√≥mo Probar el Flujo Completo

### Paso 1: Acceder al Onboarding
1. Abre `http://localhost:3055` en tu navegador
2. Ve a `/onboarding` (o crea una nueva cuenta)

### Paso 2: Completar el Onboarding
1. **Step 1 - Welcome:** Selecciona tu tipo de usuario (Agency/Company) y fuente de referencia
2. **Step 2 - Workspace:** Ingresa el nombre de tu workspace
3. **Step 3 - Project:** 
   - Ingresa el nombre del proyecto
   - Ingresa la URL del cliente (ej: `https://example.com`)
4. **Step 4 - Prompts:**
   - Ver√°s prompts sugeridos autom√°ticamente basados en la URL del cliente
   - Selecciona los prompts que quieras trackear (todos est√°n seleccionados por defecto)
   - Personaliza regi√≥n y categor√≠a para cada prompt
   - A√±ade prompts personalizados si lo deseas
   - Haz clic en "Continue"

**üöÄ EN ESTE PUNTO:**
- Los prompts se guardan en la base de datos (`prompt_tracking`)
- Se disparan an√°lisis autom√°ticos para cada prompt con los 4 LLMs
- Los an√°lisis se ejecutan en background v√≠a Edge Functions

5. **Step 5 - Results:** Vista de ranking (placeholder por ahora)
6. **Step 6 - Plan:** Selecciona un plan

### Paso 3: Verificar Prompts en Prompt Management
1. Ve a `/dashboard/prompts`
2. Deber√≠as ver todos los prompts que seleccionaste en el onboarding
3. Cada prompt muestra:
   - Texto del prompt
   - Categor√≠a
   - Regi√≥n
   - Estado (activo/inactivo)
   - Bot√≥n para ejecutar an√°lisis manualmente

### Paso 4: Ver Resultados en Citation Tracking
1. **Espera 30-60 segundos** para que los an√°lisis se completen
2. Ve a `/dashboard/citations`
3. Deber√≠as ver:
   - **M√©tricas r√°pidas:**
     - Total Citation Pages
     - My Pages Cited
     - Domains Mentioning Me
     - Your Domain Rating
   - **Gr√°fico de evoluci√≥n de citaciones**
   - **Breakdown de Domain Rating**
   - **Dominios m√°s citados**
   - **Fuentes de citaciones**

### Paso 5: Ver Detalles del An√°lisis
1. Ve a `/dashboard/analysis`
2. Ver√°s los an√°lisis ejecutados:
   - Estado (Running, Completed, Failed)
   - Plataformas (OpenAI, Gemini, Claude, Perplexity)
   - Fecha y hora de ejecuci√≥n
   - N√∫mero de citaciones encontradas

---

## üìä Estructura de Datos

### Tablas Afectadas

1. **`prompt_tracking`**
   - Almacena los prompts creados
   - Campos: `id`, `project_id`, `prompt`, `category`, `region`, `is_active`

2. **`analysis_jobs`**
   - Registra cada an√°lisis ejecutado
   - Campos: `id`, `prompt_tracking_id`, `project_id`, `status`, `total_platforms`, `completed_platforms`

3. **`ai_responses`**
   - Almacena las respuestas de cada LLM
   - Campos: `id`, `prompt_tracking_id`, `platform`, `response_text`, `status`

4. **`citations_detail`**
   - Almacena las citaciones extra√≠das
   - Campos: `id`, `ai_response_id`, `citation_text`, `sentiment`, `cited_url`

---

## üîç Debugging

### Verificar que los Prompts se Guardaron
```sql
SELECT id, prompt, category, region, is_active
FROM prompt_tracking
WHERE project_id = 'YOUR_PROJECT_ID'
ORDER BY created_at DESC;
```

### Verificar que los An√°lisis se Dispararon
```sql
SELECT id, status, total_platforms, completed_platforms, created_at
FROM analysis_jobs
WHERE project_id = 'YOUR_PROJECT_ID'
ORDER BY created_at DESC;
```

### Verificar Respuestas de los LLMs
```sql
SELECT platform, status, error_message, created_at
FROM ai_responses
WHERE project_id = 'YOUR_PROJECT_ID'
ORDER BY created_at DESC;
```

### Ver Citaciones Encontradas
```sql
SELECT cd.citation_text, ar.platform, cd.sentiment
FROM citations_detail cd
JOIN ai_responses ar ON cd.ai_response_id = ar.id
WHERE cd.project_id = 'YOUR_PROJECT_ID'
ORDER BY cd.created_at DESC
LIMIT 10;
```

---

## ‚ö†Ô∏è Consideraciones Importantes

### 1. Variables de Entorno Requeridas
Aseg√∫rate de tener configuradas las API keys en Supabase:
- `OPENAI_API_KEY`
- `GEMINI_API_KEY`
- `CLAUDE_API_KEY`
- `PERPLEXITY_API_KEY`

**C√≥mo configurar:**
1. Ve a Supabase Dashboard ‚Üí Settings ‚Üí Edge Functions
2. Agrega cada API key como "Secret"

### 2. Edge Functions Desplegadas
Aseg√∫rate de tener desplegadas las Edge Functions:
```bash
npx supabase functions deploy analyze-prompt
npx supabase functions deploy process-analysis
```

### 3. Tiempo de Ejecuci√≥n
- Los an√°lisis pueden tardar **30-60 segundos** en completarse
- Se ejecutan en paralelo para todos los LLMs
- Los resultados se procesan y se extraen las citaciones autom√°ticamente

### 4. Costos
- Cada an√°lisis consume tokens de las APIs de los LLMs
- Se recomienda monitorear el uso en el dashboard de cada proveedor

---

## üéâ Flujo Completo de Usuario

```
1. Usuario completa onboarding
   ‚Üì
2. Selecciona prompts (ej: 5 prompts)
   ‚Üì
3. Se guardan en BD ‚Üí 5 registros en `prompt_tracking`
   ‚Üì
4. Se disparan an√°lisis autom√°ticos ‚Üí 5 √ó 4 = 20 an√°lisis (5 prompts √ó 4 LLMs)
   ‚Üì
5. Edge Functions ejecutan an√°lisis en paralelo
   ‚Üì
6. Se guardan respuestas ‚Üí 20 registros en `ai_responses`
   ‚Üì
7. Se extraen citaciones ‚Üí N registros en `citations_detail`
   ‚Üì
8. Usuario ve resultados en:
   - /dashboard/prompts ‚Üí Lista de prompts
   - /dashboard/citations ‚Üí M√©tricas y citaciones
   - /dashboard/analysis ‚Üí Detalles de an√°lisis
```

---

## üìù Pr√≥ximos Pasos (Opcional)

### Mejoras Sugeridas:
1. **Notificaciones:** Agregar toast notifications cuando los an√°lisis se completen
2. **Progress Bar:** Mostrar progreso de an√°lisis en tiempo real
3. **Retry Logic:** Implementar reintento autom√°tico para an√°lisis fallidos
4. **Batch Processing:** Agrupar m√∫ltiples prompts en un solo job para mejor eficiencia
5. **Caching:** Cachear resultados para evitar an√°lisis duplicados

---

## üêõ Troubleshooting

### Problema: Los prompts no aparecen en Prompt Management
**Soluci√≥n:**
1. Verifica que `selectedProjectId` est√© definido en el contexto
2. Revisa la consola del navegador para errores
3. Verifica permisos RLS en Supabase

### Problema: Los an√°lisis no se disparan
**Soluci√≥n:**
1. Verifica que las API keys est√©n configuradas en Supabase
2. Revisa los logs de Edge Functions: `npx supabase functions logs analyze-prompt`
3. Verifica que las Edge Functions est√©n desplegadas

### Problema: No se muestran citaciones en Citation Tracking
**Soluci√≥n:**
1. Espera 60 segundos para que los an√°lisis se completen
2. Verifica que haya datos en `citations_detail` (SQL query arriba)
3. Revisa los filtros de fecha/plataforma/regi√≥n aplicados

---

## ‚úÖ Checklist de Validaci√≥n

- [ ] Los prompts se guardan correctamente en la BD
- [ ] Los prompts aparecen en `/dashboard/prompts`
- [ ] Los an√°lisis se disparan autom√°ticamente
- [ ] Los an√°lisis aparecen en `/dashboard/analysis` con estado "Running" o "Completed"
- [ ] Las citaciones aparecen en `/dashboard/citations` despu√©s de 60 segundos
- [ ] Las m√©tricas se actualizan correctamente (Total Citation Pages, etc.)
- [ ] Los filtros funcionan correctamente (fecha, plataforma, regi√≥n)

---

## üìö Recursos Adicionales

- [Documentaci√≥n de Edge Functions](./supabase/functions/README.md)
- [Gu√≠a de Despliegue](./DEPLOYMENT_GUIDE.md)
- [Schema de Base de Datos](./supabase/README.md)
- [Phase 7 Summary](./PHASE_7_SUMMARY.md)

---

**¬°Implementaci√≥n completada! üéâ**

El flujo completo est√° funcionando: desde el onboarding hasta la visualizaci√≥n de citaciones.

